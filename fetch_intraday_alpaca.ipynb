{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_ID = \"PK34H595MF2B0I7M9Y9D\"\n",
    "SECRET_KEY = \"o5Rv63Cqff6iIX0vTZGXVWjuN3c6uvXZXHvVGbmM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_intraday_stocks(stock, timeframe, start_date, end_date, output_file):\n",
    "    \"\"\"\n",
    "        Fetch intraday stock data from Alpaca API and write it to a CSV file.\n",
    "        Args:\n",
    "            stock (str): The stock symbol.\n",
    "            timeframe (str): The timeframe of the data.\n",
    "            start_date (str): The start date of the data.\n",
    "            end_date (str): The end date of the data.\n",
    "            output_file (str): The output filepath.\n",
    "    \"\"\"\n",
    "    url = f\"https://data.alpaca.markets/v2/stocks/{stock}/bars\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"APCA-API-KEY-ID\": KEY_ID,\n",
    "        \"APCA-API-SECRET-KEY\": SECRET_KEY\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"timeframe\": timeframe,\n",
    "        \"start\": start_date,\n",
    "        \"end\": end_date,\n",
    "        \"limit\": 10000,\n",
    "        \"adjustment\": \"raw\",\n",
    "        \"feed\": \"sip\",\n",
    "        \"sort\": \"asc\"\n",
    "    }\n",
    "\n",
    "    if not os.path.exists(output_file):\n",
    "        with open(output_file, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        if next_page_token:\n",
    "            params[\"page_token\"] = next_page_token\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        if \"bars\" in data:\n",
    "            with open(output_file, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                for bar in data[\"bars\"]:\n",
    "                    writer.writerow([bar[\"t\"], bar[\"o\"], bar[\"h\"], bar[\"l\"], bar[\"c\"], bar[\"v\"]])\n",
    "\n",
    "        next_page_token = data.get(\"next_page_token\")\n",
    "\n",
    "        if not next_page_token:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_intraday_stocks(\"SPY\", \"1Min\", \"2020-01-01\", \"2025-01-01\", \"./data/SPY_1min.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_intraday_crypto(token, timeframe, start_date, end_date, output_file):\n",
    "    \"\"\"\n",
    "        Fetch intraday crypto data from Alpaca API and write it to a CSV file.\n",
    "        Args:\n",
    "            token (str): The crypto token.\n",
    "            timeframe (str): The timeframe of the data.\n",
    "            start_date (str): The start date of the data.\n",
    "            end_date (str): The end date of the data.\n",
    "            output_file (str): The output filepath.\n",
    "    \"\"\"\n",
    "    url = f\"https://data.alpaca.markets/v1beta3/crypto/us/bars\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"symbols\": token,\n",
    "        \"timeframe\": timeframe,\n",
    "        \"start\": start_date,\n",
    "        \"end\": end_date,\n",
    "        \"limit\": 10000,\n",
    "        \"sort\": \"asc\"\n",
    "    }\n",
    "\n",
    "\n",
    "    # Create the output file if it doesn't exist\n",
    "    if not os.path.exists(output_file):\n",
    "        with open(output_file, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"number_of_trades\", \"vwap\"])\n",
    "\n",
    "    next_page_token = None\n",
    "\n",
    "    # Iterate API requests until all data for a given period is fetched\n",
    "    while True:\n",
    "        if next_page_token:\n",
    "            params[\"page_token\"] = next_page_token\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        # Write data to the output file\n",
    "        if \"bars\" in data:\n",
    "            with open(output_file, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                for bar in data[\"bars\"][token]:\n",
    "                    writer.writerow([\n",
    "                        bar[\"t\"],  # timestamp\n",
    "                        bar[\"o\"],  # open price\n",
    "                        bar[\"h\"],  # high price\n",
    "                        bar[\"l\"],  # low price\n",
    "                        bar[\"c\"],  # close price\n",
    "                        bar[\"v\"],  # volume\n",
    "                        bar[\"n\"],  # number of trades\n",
    "                        bar[\"vw\"]  # volume-weighted average price\n",
    "                    ])\n",
    "\n",
    "        next_page_token = data.get(\"next_page_token\")\n",
    "\n",
    "        if not next_page_token:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_intraday_crypto(\"ETH/USD\", \"5Min\", \"2020-01-01\", \"2025-01-01\", \"./data/ETH_5min.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
